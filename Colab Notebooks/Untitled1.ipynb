{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO0hlIDQqgyz4rAkiY8HxX8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":461},"id":"9oN4BLSaTCr7","executionInfo":{"status":"error","timestamp":1686403703914,"user_tz":-540,"elapsed":685,"user":{"displayName":"정다진","userId":"09257231390588010648"}},"outputId":"d6981c7f-fd18-4ac4-bb0d-1d10f665f91c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-40492fdfba9e>\u001b[0m in \u001b[0;36m<cell line: 101>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpsnr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m history = model.fit(train_dataset, epochs=10,\n\u001b[0m\u001b[1;32m    102\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1695\u001b[0m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1697\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m   1698\u001b[0m                         \u001b[0;34m\"Unexpected result of `train_function` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m                         \u001b[0;34m\"(Empty logs). Please use \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."]}],"source":["import scipy.io\n","import os\n","import PIL.Image as Image\n","import pathlib\n","import tensorflow as tf\n","import mat73\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","tf.keras.utils.get_file(\n","    'Valid_spectral.zip', 'https://github.com/caiyuanhao1998/MST-plus-plus/archive/refs/heads/main.zip', extract=True)\n","\n","mat_file_name = pathlib.Path(\n","    '/Users/dajineyland/.keras/datasets/Valid_spectral')\n","all_mats_paths = list(mat_file_name.glob('*'))\n","\n","train_path = []\n","\n","for mat_path in all_mats_paths:\n","    if str(mat_path).split('.')[-1] != \"mat\":\n","        continue\n","    train_path.append(str(mat_path))\n","\n","hyper_img = None  # Define hyper_img outside the loop\n","\n","for mat_path in train_path:\n","    mat_file = mat73.loadmat(mat_path)\n","    hyper_img = mat_file['cube']\n","    aaa = hyper_img.shape\n","\n","\n","def get_hr_and_lr(mat_path):\n","    mat_path = mat_path.numpy().decode()  # Convert path to string\n","    mat_file = mat73.loadmat(mat_path)\n","    hr = mat_file['cube']  # HR image\n","    lr = mat_file['cube']  # LR image\n","    hr = tf.convert_to_tensor(hr, dtype=tf.float32)\n","    lr = tf.convert_to_tensor(lr, dtype=tf.float32)\n","    return hr, lr\n","\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices(train_path)\n","train_dataset = train_dataset.map(lambda x: tf.py_function(get_hr_and_lr, [x], [\n","                                  tf.float32, tf.float32]))  # Wrap the function call in tf.py_function\n","\n","train_dataset = train_dataset.repeat()\n","train_dataset = train_dataset.repeat().batch(16)\n","\n","valid_dataset = tf.data.Dataset.from_tensor_slices(train_path)\n","valid_dataset = valid_dataset.map(lambda x: tf.py_function(get_hr_and_lr, [x], [\n","                                  tf.float32, tf.float32]))  # Wrap the function call in tf.py_function\n","valid_dataset = valid_dataset.repeat()\n","valid_dataset = valid_dataset.batch(1)\n","\n","\n","def REDNet(num_layers=15):\n","    conv_layers = []\n","    deconv_layers = []\n","    residual_layers = []\n","\n","    inputs = tf.keras.layers.Input(shape=(None, None, 31))\n","    conv_layers.append(tf.keras.layers.Conv2D(\n","        31, kernel_size=3, padding='same', activation='relu'))\n","\n","    for i in range(num_layers-1):\n","        conv_layers.append(tf.keras.layers.Conv2D(\n","            31, kernel_size=3, padding='same', activation='relu'))\n","        deconv_layers.append(tf.keras.layers.Conv2DTranspose(\n","            31, kernel_size=3, padding='same', activation='relu'))\n","\n","    deconv_layers.append(tf.keras.layers.Conv2DTranspose(\n","        31, kernel_size=3, padding='same'))\n","\n","    x = conv_layers[0](inputs)\n","\n","    for i in range(num_layers-1):\n","        x = conv_layers[i+1](x)\n","        residual_layers.append(deconv_layers[i](x))  # Modified line\n","\n","    residual_layers.reverse()\n","\n","    for i in range(num_layers-1):\n","        x = tf.keras.layers.Add()([x, residual_layers[i]])\n","        x = conv_layers[i+1](x)  # Modified line\n","\n","    output = tf.keras.layers.Add()([x, inputs])\n","\n","    model = tf.keras.Model(inputs=inputs, outputs=output)\n","    return model\n","\n","\n","def psnr(y_true, y_pred, max_val=1.0):\n","    mse = tf.reduce_mean(tf.square(y_true - y_pred))\n","    psnr = 10.0 * tf.math.log(max_val**2 / mse) / tf.math.log(10.0)\n","    return psnr\n","\n","\n","model = REDNet(num_layers=15)\n","model.compile(optimizer='adam', loss='mse', metrics=[psnr])\n","\n","history = model.fit(train_dataset, epochs=10,\n","                    steps_per_epoch=len(train_path) // 16,\n","                    validation_data=valid_dataset,\n","                    validation_steps=30,\n","                    verbose=2)\n","\n","plt.plot(history.history['loss'], 'b-', label='MSE')\n","plt.plot(history.history['psnr'], 'r--', label='PSNR')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()\n","\n","image_path = tf.keras.utils.get_file(\n","    'butterfly.png', 'http://bit.ly/2oAOxgH')\n","img = tf.io.read_file(image_path)\n","img = tf.image.decode_image(img, channels=3)  # Use decode_image instead of decode_jpeg\n","hr = tf.image.convert_image_dtype(img, tf.float32)\n","\n","lr = tf.image.resize(hr, [hr.shape[0]//4, hr.shape[1]//4])\n","lr = tf.image.resize(lr, [hr.shape[0], hr.shape[1]])\n","predict_hr = model.predict(np.expand_dims(lr, axis=0))\n","\n","psnr_val = psnr(np.squeeze(predict_hr, axis=-1), hr, max_val=1.0)\n","print(\"PSNR:\", psnr_val.numpy())\n","\n","# Assuming you want to visualize the 20th spectral band\n","spectral_band = 19  # Adjusted to 0-based index\n","\n","# Visualize the original HR image\n","plt.subplot(1, 3, 1)\n","plt.imshow(hr[:, :, spectral_band], cmap='gray')\n","plt.title('Original - HR (Band {})'.format(spectral_band))\n","\n","# Visualize the LR image\n","plt.subplot(1, 3, 2)\n","plt.imshow(lr[:, :, spectral_band], cmap='gray')\n","plt.title('LR (Band {})'.format(spectral_band))\n","\n","# Visualize the predicted SR image\n","plt.subplot(1, 3, 3)\n","plt.imshow(np.squeeze(predict_hr, axis=-1)\n","           [:, :, spectral_band], cmap='gray')\n","plt.title('SR (Band {})'.format(spectral_band))\n","\n","plt.show()\n"]},{"cell_type":"code","source":["import scipy.io\n","import os\n","import PIL.Image as Image\n","import pathlib\n","import tensorflow as tf\n","import mat73\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","tf.keras.utils.get_file(\n","    'Valid_spectral.zip', 'https://drive.google.com/u/0/uc?id=1FQBfDd248dCKClR-BpX5V2drSbeyhKcq&export=download', extract=True)\n","\n","mat_file_name = pathlib.Path(\n","    '/Users/dajineyland/.keras/datasets/Train_spectral')\n","all_mats_paths = list(mat_file_name.glob('*'))\n","\n","train_path = []\n","\n","for mat_path in all_mats_paths:\n","    if str(mat_path).split('.')[-1] != \"mat\":\n","        continue\n","    train_path.append(str(mat_path))\n","\n","hyper_img = None  # Define hyper_img outside the loop\n","\n","for mat_path in train_path:\n","    mat_file = mat73.loadmat(mat_path)\n","    hyper_img = mat_file['cube']\n","    aaa = hyper_img.shape\n","\n","\n","def get_hr_and_lr(mat_path):\n","    mat_path = mat_path.numpy().decode()  # Convert path to string\n","    mat_file = mat73.loadmat(mat_path)\n","    hr = mat_file['cube']  # HR image\n","    lr = mat_file['cube']  # LR image\n","    hr = tf.convert_to_tensor(hr, dtype=tf.float32)\n","    lr = tf.convert_to_tensor(lr, dtype=tf.float32)\n","    return hr, lr\n","\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices(train_path)\n","train_dataset = train_dataset.map(lambda x: tf.py_function(get_hr_and_lr, [x], [\n","                                  tf.float32, tf.float32]))  # Wrap the function call in tf.py_function\n","\n","train_dataset = train_dataset.repeat()\n","train_dataset = train_dataset.repeat().batch(16)\n","\n","valid_dataset = tf.data.Dataset.from_tensor_slices(train_path)\n","valid_dataset = valid_dataset.map(lambda x: tf.py_function(get_hr_and_lr, [x], [\n","                                  tf.float32, tf.float32]))  # Wrap the function call in tf.py_function\n","valid_dataset = valid_dataset.repeat()\n","valid_dataset = valid_dataset.batch(1)\n","\n","\n","def REDNet(num_layers=15):\n","    conv_layers = []\n","    deconv_layers = []\n","    residual_layers = []\n","\n","    inputs = tf.keras.layers.Input(shape=(None, None, 31))\n","    conv_layers.append(tf.keras.layers.Conv2D(\n","        31, kernel_size=3, padding='same', activation='relu'))\n","\n","    for i in range(num_layers-1):\n","        conv_layers.append(tf.keras.layers.Conv2D(\n","            31, kernel_size=3, padding='same', activation='relu'))\n","        deconv_layers.append(tf.keras.layers.Conv2DTranspose(\n","            31, kernel_size=3, padding='same', activation='relu'))\n","\n","    deconv_layers.append(tf.keras.layers.Conv2DTranspose(\n","        31, kernel_size=3, padding='same'))\n","\n","    x = conv_layers[0](inputs)\n","\n","    for i in range(num_layers-1):\n","        x = conv_layers[i+1](x)\n","        residual_layers.append(deconv_layers[i](x))  # Modified line\n","\n","    residual_layers.reverse()\n","\n","    for i in range(num_layers-1):\n","        x = tf.keras.layers.Add()([x, residual_layers[i]])\n","        x = conv_layers[i+1](x)  # Modified line\n","\n","    output = tf.keras.layers.Add()([x, inputs])\n","\n","    model = tf.keras.Model(inputs=inputs, outputs=output)\n","    return model\n","\n","\n","def psnr(y_true, y_pred, max_val=1.0):\n","    mse = tf.reduce_mean(tf.square(y_true - y_pred))\n","    psnr = 10.0 * tf.math.log(max_val**2 / mse) / tf.math.log(10.0)\n","    return psnr\n","\n","\n","model = REDNet(num_layers=15)\n","model.compile(optimizer='adam', loss='mse', metrics=[psnr])\n","\n","history = model.fit(train_dataset, epochs=100,\n","                    steps_per_epoch=len(train_path) // 16,\n","                    validation_data=valid_dataset,\n","                    validation_steps=30,\n","                    verbose=2)\n","\n","plt.plot(history.history['loss'], 'b-', label='MSE')\n","plt.plot(history.history['psnr'], 'r--', label='PSNR')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()\n","\n","\n","# Set up your model and other configurations\n","\n","image_path = tf.keras.utils.get_file('butterfly.png', 'http://bit.ly/2oAOxgH')\n","img = tf.io.read_file(image_path)\n","\n","# Pad the data to make its length a multiple of 4\n","img_padded = tf.pad(\n","    img, paddings=[[0, 4 - tf.shape(img)[0] % 4]], constant_values=0)\n","\n","hr = tf.io.decode_raw(img_padded, tf.float32)\n","hr = tf.reshape(hr, (hr.shape[0] // 31, hr.shape[1], 31))\n","\n","lr = tf.image.resize(hr, [hr.shape[0] // 4, hr.shape[1] // 4])\n","lr = tf.image.resize(lr, [hr.shape[0], hr.shape[1]])\n","predict_hr = model.predict(np.expand_dims(lr, axis=0))\n","\n","psnr_val = psnr(np.squeeze(predict_hr, axis=-1), hr, max_val=1.0)\n","print(\"PSNR:\", psnr_val.numpy())\n","\n","# Assuming you want to visualize the 20th spectral band\n","spectral_band = 19  # Adjusted to 0-based index\n","\n","# Visualize the original HR image\n","plt.subplot(1, 3, 1)\n","plt.imshow(hr[:, :, spectral_band], cmap='gray')\n","plt.title('Original - HR (Band {})'.format(spectral_band))\n","\n","# Visualize the LR image\n","plt.subplot(1, 3, 2)\n","plt.imshow(lr[:, :, spectral_band], cmap='gray')\n","plt.title('LR (Band {})'.format(spectral_band))\n","\n","# Visualize the predicted SR image\n","plt.subplot(1, 3, 3)\n","plt.imshow(np.squeeze(predict_hr, axis=-1)[:, :, spectral_band], cmap='gray')\n","plt.title('SR (Band {})'.format(spectral_band))\n","\n","plt.show()\n"],"metadata":{"id":"dVsGGJlJxlKa","executionInfo":{"status":"error","timestamp":1686408427074,"user_tz":-540,"elapsed":879,"user":{"displayName":"정다진","userId":"09257231390588010648"}},"outputId":"29b6a164-c958-4913-8393-785309ff96e7","colab":{"base_uri":"https://localhost:8080/","height":461}},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-a3c2bb3c9414>\u001b[0m in \u001b[0;36m<cell line: 101>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpsnr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m history = model.fit(train_dataset, epochs=100,\n\u001b[0m\u001b[1;32m    102\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1695\u001b[0m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1697\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m   1698\u001b[0m                         \u001b[0;34m\"Unexpected result of `train_function` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m                         \u001b[0;34m\"(Empty logs). Please use \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."]}]},{"cell_type":"code","source":["try:\n","    import PIL.Image as Image\n","    import pathlib\n","    import tensorflow as tf\n","except Exception:\n","    pass\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import tensorflow_hub as hub\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","\n","tf.keras.utils.get_file('bsd_images.zip',\n","                        'http://bit.ly/35pHZlC', extract=True)\n","\n","\n","image_root = pathlib.Path('/Users/dajineyland/.keras/datasets/images/')\n","all_images_paths = list(image_root.glob('*/*'))\n","# print(all_images_paths)\n","\n","# RGB_img = all_images_paths[c, -1]\n","# plt.figure(figsize=(5, 5))  # 전체 팝업창 크기\n","# for c in range(9):\n","#     plt.subplot(3, 3, c+1)  # 가로3개 세로3개 9개사진\n","#     img_test = plt.imread(all_images_paths[3])\n","#     plt.imshow(img_test)  # 이미지 보이게 하기\n","#     plt.title(all_images_paths[c])  # 사진 제목 입력\n","#     plt.axis('off')  # x좌표 y좌표 삭제\n","# plt.show()\n","\n","\n","train_path, valid_path, test_path = [], [], []\n","\n","for image_path in all_images_paths:\n","    if str(image_path).split('.')[-1] != \"jpg\":\n","        continue\n","\n","    if str(image_path).split('/')[-2] == 'train':\n","        train_path.append(str(image_path))\n","    elif str(image_path).split('/')[-2] == 'val':\n","        valid_path.append(str(image_path))\n","    else:\n","        test_path.append(str(image_path))\n","\n","\n","\n","\n","def get_hr_and_lr(image_path):\n","    img = tf.io.read_file(image_path)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.convert_image_dtype(img, tf.float32)\n","    print('222', img)\n","\n","    hr = tf.image.random_crop(img, [50, 50, 3])\n","    lr = tf.image.resize(hr, [25, 25])\n","    lr = tf.image.resize(lr, [50, 50])\n","\n","    return lr, hr\n","\n","\n","print(type(train_path))\n","\n","train_dataset = tf.data.Dataset.list_files(train_path)\n","print('1111', train_dataset)\n","train_dataset = train_dataset.map(get_hr_and_lr)\n","print(\"#2{}\".format(type(train_dataset)))\n","\n","train_dataset = train_dataset.repeat()\n","train_dataset = train_dataset.batch(16)\n","\n","valid_dataset = tf.data.Dataset.list_files(train_path)\n","valid_dataset = valid_dataset.map(get_hr_and_lr)\n","valid_dataset = valid_dataset.repeat()\n","valid_dataset = valid_dataset.batch(1)\n","# 데이터셋 일차 완성\n","\n","# REDNet-30의 정의\n","\n","\n","def REDNet(num_layers=15):  # num_layer:컨볼루션 레이어와 디컨볼루션 레이어의 수\n","    # 같은 수의 컨볼루션 레이어가 존재하기 때문에, REDNet-30이라면 num_layers=15\n","    conv_layers = []  # 컨볼루션 레이어\n","    deconv_layers = []  # 디컨볼루션 레이어\n","    residual_layers = []  # 잔류 레이어\n","\n","    # 입력 레이어의 shape에서 이미지의 높이와 너비를 None으로 지정해서 어떤 크기의 이미지라도 입력으로 받을 수 있음\n","    # 첫 번째 컨볼루션 레이어와 마지막 디컨볼루션 레이어를 제외한 레이어들은 for 문 안에서 정의해서 각 리스트에 저장\n","    # 첫번째 컨볼루션 레이어와 마지막 디컨볼루션 레이어는 필터의 수가 다른데 이는 필터의 수로 RGB 채널의 수인 3을 그대로 받기 위함\n","    #  나머지 레이어에서는 64개의 필터를 사용\n","\n","    inputs = tf.keras.layers.Input(shape=(None, None, 3))\n","    conv_layers.append(tf.keras.layers.Conv2D(\n","        3, kernel_size=3, padding='same', activation='relu'))\n","\n","    for i in range(15-1):\n","        conv_layers.append(tf.keras.layers.Conv2D(\n","            64, kernel_size=3, padding='same', activation='relu'))\n","        deconv_layers.append(tf.keras.layers.Conv2DTranspose(\n","            64, kernel_size=3, padding='same', activation='relu'))\n","\n","    deconv_layers.append(tf.keras.layers.Conv2DTranspose(\n","        3, kernel_size=3, padding='same'))\n","\n","    # 인코더 시작\n","    x = conv_layers[0](inputs)  # 결과: x는 입력 레이어에 첫 번째 컨볼루션 레이어를 적용한 결과\n","\n","    for i in range(15-1):\n","        x = conv_layers[i+1](x)\n","        if i % 2 == 0:\n","            residual_layers.append(x)\n","\n","    # for 문 안에서 x에 나머지 컨볼루션 레이어를 계속 적용시키며, 짝수번재 컨볼루션 레이어를 지날 때마다 x를 잔류 레이어 리스트에도 저장\n","    # 잔류 레이어에 x를 저장한 다음 스텝에서 x는 다시 컨볼루션 레이어를 통과해서 새로운 값이 되지만 잔류 레이어에 이미 저장된 값은 사라지지 않음\n","\n","    # 디코더 시작\n","    for i in range(15-1):\n","        if i % 2 == 1:\n","            x = tf.keras.layers.Add()([x, residual_layers.pop()])\n","            x = tf.keras.layers.Activation('relu')(x)\n","        x = deconv_layers[i](x)\n","\n","    x = deconv_layers[-1](x)\n","\n","    # 홀수 번째의 디컨볼루션 레이어를 통과할 경우 잔류 레이어 리스트에 저장돼 있던 값을 residual_layers.pop()으로 뒤에서부터 하나씩 가져옴\n","    # 그 다음 합연산과 ReLU 활성화함수를 통과한 후 다음 디컨볼루션 레이어에 연결 (짝수 번째일 때는 디컨볼루션 레이어만 연결)\n","\n","    # x라는 변수에 레이어를 계속 적용해서 함수형 API를 사용\n","    # 마지막에 x는 모든 레이어가 적용된 결과가 되기 때문에 모델의 출력 => 하나의 변수 이름을 재사용하여 레이어 적용\n","\n","    model = tf.keras.Model(inputs=inputs, outputs=x)\n","    # tf.keras의 함수형 API로 Model을 만들기 위해서는 입력과 출력만 지정하면 됨\n","    # 입력인 inputs는 함수의 가장 앞에서 정의한 입력 레이어로, 출력인 outputs는 지금까지 레이어 연산을 쭉 따라온 변수 이름인 x로 넣고, model을 반환\n","    return model\n","\n","\n","def psnr_metric(y_true, y_pred):\n","    return tf.image.psnr(y_true, y_pred, max_val=1.0)\n","# y_true: 정답에 해당하는 값\n","# y_pred: 네트워크가 학습 결과 예측한 값\n","# 이 둘의 tf.image.psnr()을 계산해서 반환하는 것이 psnr_metric() 함수의 역할\n","\n","\n","model = REDNet(15)\n","model.compile(optimizer=tf.optimizers.legacy.Adam(0.0001),\n","              loss='mse', metrics=[psnr_metric])\n","# REDNet() 함수로 네트워크를 초기화하고 컴파일\n","\n","tf.keras.utils.plot_model(model)\n","# 컴파일된 네트워크 시각화를 작성\n","\n","history = model.fit_generator(train_dataset,\n","                              epochs=10000,\n","                              steps_per_epoch=len(train_path)//16,\n","                              validation_data=valid_dataset,\n","                              validation_steps=len(valid_path),\n","                              verbose=2)\n","# 네트워크를 학습\n","# Dataset를 이용한 학습은 fit() 함수 대신 fit_generator() 함수를 사용\n","# Dataset에 repeat() 함수를 사용했기 때문에 한 번의 에포크에 몇 개의 데이터를 학습시킬지를 지정하는 steps_per_epoch인수를 설정\n","# batch size가 16이기 때문에 steps_per_epoch는 len(train_path)//16으로 훈련 데이터의 크기를 batch size로 나눕니다.\n","# verbose = 2 : 출력제한에 걸리지 않도록 하며, 진행 상황 애니메이션은 생략하고 각 에포크의 결과만 출력\n","# 학습 결과 :  훈련 데이터의 PSNR은 31~32, 검증데이터의 29-32정도\n","\n","plt.plot(history.history['psnr_metric'], 'b-', label='psnr')\n","plt.plot(history.history['val_psnr_metric'], 'r--', label='val_psnr')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()\n","# 학습 결과 확인\n","\n","image_path = tf.keras.utils.get_file('butterfly.png', 'http://bit.ly/2oAOxgH')\n","img = tf.io.read_file(image_path)\n","img = tf.image.decode_jpeg(img, channels=3)\n","hr = tf.image.convert_image_dtype(img, tf.float32)\n","\n","lr = tf.image.resize(hr, [hr.shape[0]//4, hr.shape[1]//4])\n","lr = tf.image.resize(lr, [hr.shape[0], hr.shape[1]])\n","predict_hr = model.predict(np.expand_dims(lr, axis=0))\n","\n","print(tf.image.psnr(np.squeeze(predict_hr, axis=0), hr, max_val=1.0))\n","print(tf.image.psnr(lr, hr, max_val=1.0))\n","# PSNR 수치 모두 학습할수록 증가하는 경향 => 이렇게 학습된 데이터가 실제 이미지를 어떻게 복원하는지 확인\n","\n","\n","plt.figure(figsize=(16, 6))\n","plt.subplot(1, 3, 1)\n","plt.imshow(hr)\n","plt.title('original - hr')\n","\n","plt.subplot(1, 3, 2)\n","plt.imshow(lr)\n","plt.title('lr')\n","\n","plt.subplot(1, 3, 3)\n","plt.imshow(np.squeeze(predict_hr, axis=0))\n","plt.title('sr')\n","\n","plt.show()\n","# 테스트 이미지에 대한 초해상도 결과 확인\n","# 첫번째 사진 : 이미지의 원본, 두번째 사진 : 저해상도, 세번째 사진 : 복원된 이미지\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":693},"id":"erM-kA60VfSz","executionInfo":{"status":"error","timestamp":1686401721745,"user_tz":-540,"elapsed":2163,"user":{"displayName":"정다진","userId":"09257231390588010648"}},"outputId":"9564b5fe-fc3b-4e77-d0b6-1e7e64560ecf"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from http://bit.ly/35pHZlC\n","37520292/37520292 [==============================] - 0s 0us/step\n","<class 'list'>\n"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-04415286f54a>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1111'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_hr_and_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mlist_files\u001b[0;34m(file_pattern, shuffle, seed, name)\u001b[0m\n\u001b[1;32m   1287\u001b[0m           string_ops.reduce_join(file_pattern, separator=\", \"), name=\"message\")\n\u001b[1;32m   1288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m       assert_not_empty = control_flow_ops.Assert(\n\u001b[0m\u001b[1;32m   1290\u001b[0m           condition, [message], summarize=1, name=\"assert_not_empty\")\n\u001b[1;32m   1291\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massert_not_empty\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mAssert\u001b[0;34m(condition, data, summarize, name)\u001b[0m\n\u001b[1;32m    154\u001b[0m       \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_n_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mdata_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_summarize_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m       raise errors.InvalidArgumentError(\n\u001b[0m\u001b[1;32m    157\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: '"]}]},{"cell_type":"code","source":["!pip install mat73"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-iBwaZRTTaeO","executionInfo":{"status":"ok","timestamp":1686400220753,"user_tz":-540,"elapsed":7449,"user":{"displayName":"정다진","userId":"09257231390588010648"}},"outputId":"90d6c796-d58d-4ed5-fc99-5bbf115458b5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mat73\n","  Downloading mat73-0.60-py3-none-any.whl (19 kB)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from mat73) (3.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mat73) (1.22.4)\n","Installing collected packages: mat73\n","Successfully installed mat73-0.60\n"]}]}]}