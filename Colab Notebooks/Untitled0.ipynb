{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNu1QlWsid73mBcRW7KYLpV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"C3IPRpJ5cbdt"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"uScNDkIWMj5W","executionInfo":{"status":"error","timestamp":1684139345863,"user_tz":-540,"elapsed":561,"user":{"displayName":"정다진","userId":"09257231390588010648"}},"outputId":"83394f00-a759-4c97-8385-6136dc5a74a3"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-1021de6afff1>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"mat\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mtrain_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'image_path' is not defined"]}],"source":["try:\n","    import PIL.Image as Image\n","    import pathlib\n","    import tensorflow as tf\n","except Exception:\n","    pass\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import tensorflow_hub as hub\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","\n","tf.keras.utils.get_file(\n","    'Valid_spectral.zip', 'https://github.com/caiyuanhao1998/MST-plus-plus', extract=True)\n","\n","\n","image_root = pathlib.Path('/Users/dajineyland/.keras/datasets/Valid_spectral')\n","all_images_paths = list(image_root.glob('*'))\n","# print(all_images_paths)\n","\n","# RGB_img = all_images_paths[c, -1]\n","# plt.figure(figsize=(5, 5))  # 전체 팝업창 크기\n","# for c in range(9):\n","#     plt.subplot(3, 3, c+1)  # 가로3개 세로3개 9개사진\n","#     img_test = plt.imread(all_images_paths[3])\n","#     plt.imshow(img_test)  # 이미지 보이게 하기\n","#     plt.title(all_images_paths[c])  # 사진 제목 입력\n","#     plt.axis('off')  # x좌표 y좌표 삭제\n","# plt.show()\n","\n","\n","train_path = []\n","\n","for image_path in all_images_paths:\n","    if str(image_path).split('.')[-1] != \"mat\":\n","        continue\n","train_path.append(str(image_path))\n","\n","\n","    # print(\"#image_path: {0}\".format(image_path))\n","# print(\"#train_path\", train_path)\n","\n","# if str(image_path).split('/')[-2] == 'train':\n","#     train_path.append(str(image_path))\n","# elif str(image_path).split('/')[-2] == 'val':\n","#     valid_path.append(str(image_path))\n","# else:\n","#     test_path.append(str(image_path))\n","\n","\n","def get_hr_and_lr(image_path):\n","    img = tf.io.read_file(image_path)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.convert_image_dtype(img, tf.float32)\n","\n","    hr = tf.image.random_crop(img, [50, 50, 3])\n","    lr = tf.image.resize(hr, [25, 25])\n","    lr = tf.image.resize(lr, [50, 50])\n","\n","    return lr, hr\n","\n","\n","train_dataset = tf.data.Dataset.list_files(image_path)\n","train_dataset = train_dataset.map(get_hr_and_lr)\n","train_dataset = train_dataset.repeat()\n","train_dataset = train_dataset.batch(16)\n","\n","valid_dataset = tf.data.Dataset.list_files(image_path)\n","valid_dataset = valid_dataset.map(get_hr_and_lr)\n","valid_dataset = valid_dataset.repeat()\n","valid_dataset = valid_dataset.batch(1)\n","# 데이터셋 일차 완성\n","\n","# REDNet-30의 정의\n","\n","\n","def REDNet(num_layers=15):  # num_layer:컨볼루션 레이어와 디컨볼루션 레이어의 수\n","    # 같은 수의 컨볼루션 레이어가 존재하기 때문에, REDNet-30이라면 num_layers=15\n","    conv_layers = []  # 컨볼루션 레이어\n","    deconv_layers = []  # 디컨볼루션 레이어\n","    residual_layers = []  # 잔류 레이어\n","\n","    # 입력 레이어의 shape에서 이미지의 높이와 너비를 None으로 지정해서 어떤 크기의 이미지라도 입력으로 받을 수 있음\n","    # 첫 번째 컨볼루션 레이어와 마지막 디컨볼루션 레이어를 제외한 레이어들은 for 문 안에서 정의해서 각 리스트에 저장\n","    # 첫번째 컨볼루션 레이어와 마지막 디컨볼루션 레이어는 필터의 수가 다른데 이는 필터의 수로 RGB 채널의 수인 3을 그대로 받기 위함\n","    #  나머지 레이어에서는 64개의 필터를 사용\n","\n","    inputs = tf.keras.layers.Input(shape=(None, None, 3))\n","    conv_layers.append(tf.keras.layers.Conv2D(\n","        3, kernel_size=3, padding='same', activation='relu'))\n","\n","    for i in range(15-1):\n","        conv_layers.append(tf.keras.layers.Conv2D(\n","            64, kernel_size=3, padding='same', activation='relu'))\n","        deconv_layers.append(tf.keras.layers.Conv2DTranspose(\n","            64, kernel_size=3, padding='same', activation='relu'))\n","\n","    deconv_layers.append(tf.keras.layers.Conv2DTranspose(\n","        3, kernel_size=3, padding='same'))\n","\n","    # 인코더 시작\n","    x = conv_layers[0](inputs)  # 결과: x는 입력 레이어에 첫 번째 컨볼루션 레이어를 적용한 결과\n","\n","    for i in range(15-1):\n","        x = conv_layers[i+1](x)\n","        if i % 2 == 0:\n","            residual_layers.append(x)\n","\n","    # for 문 안에서 x에 나머지 컨볼루션 레이어를 계속 적용시키며, 짝수번재 컨볼루션 레이어를 지날 때마다 x를 잔류 레이어 리스트에도 저장\n","    # 잔류 레이어에 x를 저장한 다음 스텝에서 x는 다시 컨볼루션 레이어를 통과해서 새로운 값이 되지만 잔류 레이어에 이미 저장된 값은 사라지지 않음\n","\n","    # 디코더 시작\n","    for i in range(15-1):\n","        if i % 2 == 1:\n","            x = tf.keras.layers.Add()([x, residual_layers.pop()])\n","            x = tf.keras.layers.Activation('relu')(x)\n","        x = deconv_layers[i](x)\n","\n","    x = deconv_layers[-1](x)\n","\n","    # 홀수 번째의 디컨볼루션 레이어를 통과할 경우 잔류 레이어 리스트에 저장돼 있던 값을 residual_layers.pop()으로 뒤에서부터 하나씩 가져옴\n","    # 그 다음 합연산과 ReLU 활성화함수를 통과한 후 다음 디컨볼루션 레이어에 연결 (짝수 번째일 때는 디컨볼루션 레이어만 연결)\n","\n","    # x라는 변수에 레이어를 계속 적용해서 함수형 API를 사용\n","    # 마지막에 x는 모든 레이어가 적용된 결과가 되기 때문에 모델의 출력 => 하나의 변수 이름을 재사용하여 레이어 적용\n","\n","    model = tf.keras.Model(inputs=inputs, outputs=x)\n","    # tf.keras의 함수형 API로 Model을 만들기 위해서는 입력과 출력만 지정하면 됨\n","    # 입력인 inputs는 함수의 가장 앞에서 정의한 입력 레이어로, 출력인 outputs는 지금까지 레이어 연산을 쭉 따라온 변수 이름인 x로 넣고, model을 반환\n","    return model\n","\n","\n","def psnr_metric(y_true, y_pred):\n","    return tf.image.psnr(y_true, y_pred, max_val=1.0)\n","# y_true: 정답에 해당하는 값\n","# y_pred: 네트워크가 학습 결과 예측한 값\n","# 이 둘의 tf.image.psnr()을 계산해서 반환하는 것이 psnr_metric() 함수의 역할\n","\n","\n","model = REDNet(15)\n","model.compile(optimizer=tf.optimizers.legacy.Adam(0.0001),\n","              loss='mse', metrics=[psnr_metric], run_eagerly=True)\n","# REDNet() 함수로 네트워크를 초기화하고 컴파일\n","\n","tf.keras.utils.plot_model(model)\n","# 컴파일된 네트워크 시각화를 작성\n","\n","history = model.fit_generator(train_dataset,\n","                              epochs=1000,\n","                              steps_per_epoch=len(train_path)//16,\n","                              validation_data=valid_dataset,\n","                              validation_steps=len(train_path),\n","                              verbose=2)\n","# 네트워크를 학습\n","# Dataset를 이용한 학습은 fit() 함수 대신 fit_generator() 함수를 사용\n","# Dataset에 repeat() 함수를 사용했기 때문에 한 번의 에포크에 몇 개의 데이터를 학습시킬지를 지정하는 steps_per_epoch인수를 설정\n","# batch size가 16이기 때문에 steps_per_epoch는 len(train_path)//16으로 훈련 데이터의 크기를 batch size로 나눕니다.\n","# verbose = 2 : 출력제한에 걸리지 않도록 하며, 진행 상황 애니메이션은 생략하고 각 에포크의 결과만 출력\n","# 학습 결과 :  훈련 데이터의 PSNR은 31~32, 검증데이터의 29-32정도\n","\n","plt.plot(history.history['psnr_metric'], 'b-', label='psnr')\n","plt.plot(history.history['val_psnr_metric'], 'r--', label='val_psnr')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()\n","# 학습 결과 확인\n","\n","image_path = tf.keras.utils.get_file('butterfly.png', 'http://bit.ly/2oAOxgH')\n","img = tf.io.read_file(image_path)\n","img = tf.image.decode_jpeg(img, channels=3)\n","hr = tf.image.convert_image_dtype(img, tf.float32)\n","\n","lr = tf.image.resize(hr, [hr.shape[0]//4, hr.shape[1]//4])\n","lr = tf.image.resize(lr, [hr.shape[0], hr.shape[1]])\n","predict_hr = model.predict(np.expand_dims(lr, axis=0))\n","\n","print(tf.image.psnr(np.squeeze(predict_hr, axis=0), hr, max_val=1.0))\n","print(tf.image.psnr(lr, hr, max_val=1.0))\n","# PSNR 수치 모두 학습할수록 증가하는 경향 => 이렇게 학습된 데이터가 실제 이미지를 어떻게 복원하는지 확인\n","\n","\n","plt.figure(figsize=(16, 6))\n","plt.subplot(1, 3, 1)\n","plt.imshow(hr)\n","plt.title('original - hr')\n","\n","plt.subplot(1, 3, 2)\n","plt.imshow(lr)\n","plt.title('lr')\n","\n","plt.subplot(1, 3, 3)\n","plt.imshow(np.squeeze(predict_hr, axis=0))\n","plt.title('sr')\n","\n","plt.show()\n","# 테스트 이미지에 대한 초해상도 결과 확인\n","# 첫번째 사진 : 이미지의 원본, 두번째 사진 : 저해상도, 세번째 사진 : 복원된 이미지\n"]}]}